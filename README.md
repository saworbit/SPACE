<div align="center">

# ğŸš€ SPACE MVP
## Storage Platform for Adaptive Computational Ecosystems

> **âœ¨ One capsule. Infinite views.** The future of storage starts with a single primitive that breaks down protocol silos.

[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![Rust](https://img.shields.io/badge/rust-1.78%2B-orange.svg)](https://www.rust-lang.org)
[![Status](https://img.shields.io/badge/status-Phase%203.3%20Advanced%20Security-green.svg)](https://github.com/your-org/space)

---

### ğŸ“‘ Table of Contents
[ğŸ’¡ The Big Idea](#-the-big-idea) â€¢ [ğŸ“Š Current Status](#-current-status-phase-33---advanced-security-landed) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ—ï¸ Architecture](#ï¸-architecture) â€¢ [ğŸ” Security](#-security--encryption) â€¢ [ğŸ—ºï¸ Roadmap](#ï¸-roadmap) â€¢ [âš¡ Performance](#-performance-characteristics) â€¢ [ğŸ§ª Testing](#-testing) â€¢ [ğŸ“š Learn More](#-learn-more)

</div>

---

## ğŸ’¡ The Big Idea

Traditional storage forces you into boxes: **block** *or* **file** *or* **object**. Different APIs, separate data copies, endless complexity.

**SPACE flips the script.** Everything is a **capsule** -- a universal 128-bit ID that can be viewed through *any* protocol:

| Protocol | Access Method |
|----------|---------------|
| ğŸ”² **Block** | NVMe-oF, iSCSI |
| ğŸ“ **File** | NFS, SMB |
| ğŸ—„ï¸ **Object** | S3 API |

**âœ¨ The same capsule. Three different views. Zero data copies.**

---

## ğŸ“Š Current Status: Phase 3.3 - Advanced Security Landed

**ğŸ¯ Status:** Phase 3.3 Complete - Advanced Security hardened!

**âœ… What exists NOW:**
- ğŸ”® Universal capsule storage with persistent metadata
- ğŸ’» CLI create/read operations
- ğŸŒ S3-compatible REST API (protocol view proof-of-concept)
- ğŸ“‚ NFS + block protocol views (namespace + volume facades)
- ğŸ—œï¸ Adaptive compression (LZ4/Zstd with entropy detection)
- âš¡ Zero-copy compression/dedup pipeline using `Cow<[u8]>` + `bytes::Bytes` shared buffers
- ğŸ”— Content-addressed deduplication (post-compression)
- ğŸ” **XTS-AES-256 encryption with BLAKE3-MAC integrity**
- ğŸ¯ **Deterministic encryption preserving deduplication**
- ğŸ”‘ **Key management with rotation support**
- ğŸ—‘ï¸ **Reference-counted garbage collection with metadata reclamation**
- ğŸ§© **Modular trait-based pipeline for read/delete/GC (feature `modular_pipeline`)**
- âš™ï¸ **Tokio-powered async write pipeline** (Cargo feature `pipeline_async`) with staged NVRAM transactions, bounded concurrency, and `tracing` metrics
- ğŸŒ¸ **Counting Bloom filters** in the registry to prescreen dedup candidates at multi-million scale
- ğŸ“ **Immutable audit log** with BLAKE3 hash chaining + optional TSA anchoring (`security::audit_log`)
- ğŸ›¡ï¸ **SPIFFE + mTLS eBPF gateway** when the `advanced-security` feature is enabled (`protocol-s3`)
- ğŸ”® **Post-quantum crypto toggle** (Kyber + AES hybrid) selectable via `Policy::crypto_profile`
- ğŸ—ï¸ **Dedicated `security` module** so Bloom/audit/PQ/eBPF logic stays feature gated

**ğŸ”œ What's coming next:**
- ğŸ”„ Replication & clustering
- ğŸ“‹ Policy compiler

## âœ¨ What This MVP Proves

**ğŸ‰ Phase 3.3 Complete: Compression âœ… | Dedup âœ… | Protocol Views âœ… | Advanced Security âœ…**

### ğŸ“¦ Phase 1: Core Storage âœ…
- âœ… **Universal Capsule IDs** -- 128-bit UUIDs as the single storage primitive
- âœ… **Persistent NVRAM Log** -- Append-only durability with automatic fsync
- âœ… **Intelligent Segmentation** -- Auto-split to 4MB chunks for efficiency
- âœ… **CLI Tool** -- Create and read capsules from the command line
- âœ… **JSON Metadata** -- Human-readable registry for debugging and inspection

### ğŸ—œï¸ Phase 2.1: Compression âœ…
- âœ… **LZ4 Fast Compression** -- Sub-millisecond compression for hot data
- âœ… **Zstd Balanced Compression** -- High compression ratios for cold data
- âœ… **Entropy Detection** -- Skip compression on random/pre-compressed data
- âœ… **Policy-Driven** -- Configure compression per capsule with presets
- âœ… **Zero-Copy Fast-Path** -- Borrow slices when compression can reuse input to avoid extra allocations

### ğŸ”— Phase 2.2: Deduplication âœ…
- âœ… **Content-Addressed Storage** -- BLAKE3 hashing of compressed segments
- âœ… **Automatic Dedup** -- Reuse identical segments across capsules
- âœ… **Space Savings Tracking** -- Monitor dedup ratios and bytes saved
- âœ… **Post-Compression Dedup** -- Foundation for "dedupe over ciphertext"
- âœ… **Borrowed Hashing Path** -- Zero-copy buffers flow through hashing/encryption without cloning

### ğŸŒ Phase 2.3: Protocol Views âœ…
- âœ… **S3 REST API** -- PUT/GET/HEAD/LIST/DELETE operations
- âœ… **Protocol Abstraction** -- Same capsule accessible via multiple APIs
- âœ… **NFS namespace view** - Hierarchical directories backed by capsules
- âœ… **Block volume view** - Logical LUN facade with copy-on-write rewrites

### ğŸ” Phase 3.1: Encryption & Integrity âœ…
- âœ… **XTS-AES-256 Encryption** -- Per-segment encryption with hardware acceleration
- âœ… **BLAKE3-MAC Integrity** -- Tamper detection with keyed MAC
- âœ… **Deterministic Encryption** -- Content-derived tweaks preserve deduplication
- âœ… **Key Management** -- Version-tracked key derivation with rotation support
- âœ… **Zero-Trust Design** -- Keys from environment, zeroized on drop

### ğŸ›¡ï¸ Phase 3.3: Advanced Security âœ…
- ğŸŒ¸ **Counting Bloom filters** guard the registry from multi-million entry dedup explosions while keeping false positives ~0.1%.
- ğŸ“ **Immutable audit log** persists every capsule/segment event with BLAKE3 hash chaining plus optional TSA webhooks (`security::audit_log`).
- ğŸ”’ **Zero-trust ingress** â€” the SPIFFE + mTLS gateway (feature `advanced-security`) layers an eBPF policy filter and refreshable workload allow-list.
- ğŸ”® **Post-quantum crypto toggle** â€” `Policy::crypto_profile = HybridKyber` wraps AES keys with Kyber ML-KEM material for forward secrecy.
- ğŸ—ï¸ **Modular security crate** keeps Bloom/Audit/PQ/eBPF code feature gated so sovereign deployments can opt in/out cleanly.

---

## ğŸš€ Quick Start

### ğŸ’» System Requirements
- ğŸ§ Linux, macOS, or Windows
- ğŸ¦€ Rust 1.78+
- ğŸ’¾ 2GB free disk space

### ğŸ”¨ Build
```bash
cargo build --release
```

### ğŸ” Setup Encryption (Optional)
```bash
# Generate master key for encryption
export SPACE_MASTER_KEY=$(openssl rand -hex 32)

# Verify setup
echo ${#SPACE_MASTER_KEY}  # Should output 64
```

### ğŸ›¡ï¸ Advanced Security Setup (Optional)
```bash
# Opt-in to Bloom/audit/SPIFFE/PQ via the feature flag
cargo build --features advanced-security

# Registry tuning (optional)
export SPACE_BLOOM_CAPACITY=10000000        # default: 10M entries
export SPACE_BLOOM_FPR=0.001                # default: 0.1% false positives

# Audit log (optional TSA batches every 100 events)
export SPACE_AUDIT_LOG=/var/lib/space/space.audit.log
export SPACE_AUDIT_FLUSH=5                  # fsync every 5 events
export SPACE_TSA_ENDPOINT=https://tsa.local/submit
export SPACE_TSA_API_KEY=demo-token

# SPIFFE + mTLS ingress (protocol-s3)
export SPACE_ALLOWED_SPIFFE_IDS="spiffe://demo/client-a,spiffe://demo/client-b"
export SPACE_SPIFFE_ENDPOINT=ws://127.0.0.1:9001/identities
export SPACE_SPIFFE_HEADER=x-spiffe-id
export SPACE_SPIFFE_REFRESH_SECS=30
export SPACE_BPF_PROGRAM=/opt/space/gateway.bpf.o   # optional on Linux

# Kyber hybrid toggle for PQ readiness
export SPACE_KYBER_KEY_PATH=/var/lib/space/space.kyber.key
```

Run the zero-trust S3 test on Linux (aya/ebpf requires a unix target):
```bash
cargo test -p protocol-s3 --features advanced-security
```

### ğŸ“ Create a Capsule
```bash
# Basic usage (no encryption)
echo "Hello SPACE!" > test.txt
./target/release/spacectl create --file test.txt

# Output:
# [x] Capsule created: 550e8400-e29b-41d4-a716-446655440000
#    Size: 13 bytes
#     Segment 0: 1.85x compression (13 -> 7 bytes, lz4_1)
# [x] Capsule 550e8400-...: 1.85x compression, 0 dedup hits
```

### ğŸ“– Read It Back
```bash
# Replace UUID with your capsule ID
./target/release/spacectl read 550e8400-e29b-41d4-a716-446655440000 > output.txt
```

### ğŸ”— Test Deduplication
```bash
# Create file with repeated content (Bash)
echo "SPACE STORAGE " > test_repeated.txt
for i in {1..5000}; do echo "SPACE STORAGE " >> test_repeated.txt; done

# PowerShell alternative:
# "SPACE STORAGE " * 5000 | Out-File test_repeated.txt

# Create first capsule
./target/release/spacectl create --file test_repeated.txt

# Create second capsule (same content - watch for dedup!)
./target/release/spacectl create --file test_repeated.txt

# Expected Output:
# *  Dedup hit: Reusing segment 1 (saved 4194304 bytes)
# [x] Capsule ...: 5.23x compression, 1 dedup hits (4194304 bytes saved)
```

### âš¡ Enable Async Pipeline & Metrics (optional)
```bash
# Build with async pipeline enabled
cargo build --features pipeline_async

# Run CLI with runtime-managed async pipeline and info-level tracing
RUST_LOG=info ./target/debug/spacectl create --file test.txt

# Run feature-gated tests
cargo test -p capsule-registry --features pipeline_async
```

### ğŸ§© Opt in to the Modular Pipeline (compression/dedup/encryption traits)
```bash
# Build everything with the modular orchestrator available
cargo build --features modular_pipeline

# Create or read capsules via the trait-based pipeline
./target/release/spacectl create --file demo.txt --modular
./target/release/spacectl read 550e8400-e29b-41d4-a716-446655440000 --modular > output.txt

# Serve the S3 view against the modular backend
./target/release/spacectl serve-s3 --port 8080 --modular

# Legacy callers can still flip back at runtime, even when the feature is enabled
SPACE_DISABLE_MODULAR_PIPELINE=1 ./target/release/spacectl create --file demo.txt
```

The modular path instantiates `compression`, `dedup`, `encryption`, and `storage` crates through shared traits, while `WritePipeline` automatically delegates reads/writes/GC to the new orchestrator whenever the feature is compiled in. Protocol crates (e.g., S3) and the CLI share a common helper (`registry_pipeline_from_env`) so they all exercise the same code paths. Disable the feature entirely for leaner binaries via `--no-default-features` or by omitting `--features modular_pipeline`.

### ğŸŒ Start S3 Server
```bash
./target/release/spacectl serve-s3 --port 8080

# In another terminal, test S3 API
curl -X PUT http://localhost:8080/demo-bucket/hello.txt -d "Hello from S3!"
curl http://localhost:8080/demo-bucket/hello.txt
```

---

## ğŸ—ï¸ Architecture
```
+-------------------------------------------------------------+
|                  ğŸ’» spacectl (CLI)                          |
|           Your interface to the storage fabric               |
+--------------------+----------------------------------------+
                     |
+--------------------v----------------------------------------+
|            ğŸ“‹ CapsuleRegistry                               |
|      Manages capsule metadata & segment mappings            |
|      Content Store: ContentHash -> SegmentId                 |
+--------------------------------------------------------------+
|            âš™ï¸ WritePipeline                                 |
|   Segments -> Compress -> Hash -> Encrypt -> MAC -> Dedup -> Store|
+--------------------+----------------------------------------+
                     |
+--------------------v----------------------------------------+
|               ğŸ’¾ NvramLog                                   |
|         Durable append-only segment storage                  |
+--------------------------------------------------------------+
```

### ğŸ”„ Data Flow (Write Path with Compression, Encryption & Dedup)
```
Input File
    |
    +-> Split into 4MB segments
    |
    +-> Compress each segment (LZ4/Zstd)
    |   +-> Skip if high entropy (random data)
    |
    +-> Hash compressed data (BLAKE3)
    |
    +-> Encrypt (if enabled)
    |   +- Derive deterministic tweak from hash
    |   +- XTS-AES-256 encryption
    |
    +-> Compute MAC (BLAKE3-keyed)
    |
    +-> Check content store
    |   +- Hit?  -> Reuse existing segment (dedup!)
    |   +- Miss? -> Write new segment
    |
    +-> Append to NVRAM log (fsync)
    |
    +-> Update metadata registry
         |
         +-> Return CapsuleID to user
```

---

## ğŸ“ Project Structure
```
space/
+-- crates/
|   +-- common/              # Shared types (CapsuleId, SegmentId, Policy)
|   +-- encryption/          # NEW: XTS-AES-256 + BLAKE3-MAC + Key management
|   |   +-- src/
|   |   |   +-- lib.rs       # Module exports
|   |   |   +-- error.rs     # Error types
|   |   |   +-- policy.rs    # EncryptionPolicy & metadata
|   |   |   +-- keymanager.rs# Key derivation & rotation
|   |   |   +-- xts.rs       # XTS-AES-256 encryption
|   |   |   +-- mac.rs       # BLAKE3-MAC integrity
|   |   +-- tests/           # 53 passing tests
|   +-- capsule-registry/    # Metadata + write pipeline + dedup + encryption
|   |   +-- src/
|   |   |   +-- lib.rs       # Registry with content store
|   |   |   +-- pipeline.rs  # Write/read with encryption integration
|   |   |   +-- compression.rs # LZ4/Zstd adaptive compression
|   |   |   +-- dedup.rs     # BLAKE3 hashing & stats
|   |   +-- tests/
|   |       +-- integration_test.rs
|   |       +-- dedup_test.rs
|   +-- nvram-sim/           # Persistent log storage simulator
|   +-- protocol-s3/         # S3-compatible REST API
|   +-- spacectl/            # Command-line interface
+-- docs/
|   +-- architecture.md
|   +-- patentable_concepts.md
|   +-- future_state_architecture.md
|   +-- DEDUP_IMPLEMENTATION.md        # Phase 2.2 details
|   +-- ENCRYPTION_IMPLEMENTATION.md   # NEW: Phase 3 details
+-- Cargo.toml               # Workspace configuration
+-- demo_s3.sh               # S3 protocol demo
+-- test_dedup.sh            # Deduplication demo (Bash)
+-- README.md                # You are here
```

### âš™ï¸ Runtime Files (Auto-Generated)
```
space.metadata         -> Capsule registry + content store (JSON)
space.nvram            -> Raw segment data (encrypted if enabled)
space.nvram.segments   -> Segment metadata with encryption info (JSON)
```

---

## ğŸ§ª Testing
```bash
# Run all tests
cargo test --workspace

# Run with output to see compression/dedup/encryption stats
cargo test --workspace -- --nocapture

# Run encryption tests
cargo test -p encryption -- --nocapture

# Run dedup-specific tests
cargo test --test dedup_test -- --nocapture

# Exercise the modular pipeline prototype (compression/dedup/encryption traits)
cargo test -p capsule-registry --features modular_pipeline -- --nocapture

# Run S3 protocol tests
cargo test -p protocol-s3 -- --nocapture

# Zero-trust ingress tests (Linux + advanced-security feature)
cargo test -p protocol-s3 --features advanced-security -- --nocapture


# Automated dedup demo (Linux/macOS/Git Bash)
./test_dedup.sh

# Automated dedup demo (Windows PowerShell)
.\test_dedup.ps1
```

**âœ… Test Coverage:**
- âœ… Write/read round-trip with compression
- âœ… Multi-segment handling
- âœ… Metadata persistence
- âœ… NVRAM log recovery
- âœ… Compression entropy detection
- âœ… Deduplication across capsules
- âœ… S3 protocol views (PUT/GET/HEAD/LIST/DELETE)
- âœ… **Encryption/decryption round-trip**
- âœ… **MAC integrity verification**
- âœ… **Key derivation & rotation**
- âœ… **Deterministic encryption for dedup**

---

## ğŸ’¡ Why This Matters

### âš ï¸ Traditional Storage Problems

| Problem | SPACE Solution |
|---------|----------------|
| ğŸ”’ Protocol lock-in (block vs file vs object) | âœ… **One capsule, multiple views** |
| ğŸ“¦ Data duplication across tiers | âœ… **Content-addressed deduplication** |
| ğŸ”„ Complex migration between protocols | âœ… **Instant protocol switching** |
| ğŸšš Forklift upgrades required | âœ… **Microservice-based evolution** |
| ğŸ›¡ï¸ Security bolted on afterward | âœ… **Built-in encryption per segment** |
| ğŸ” Encryption breaks deduplication | âœ… **Deterministic tweaks preserve dedup** |
| ğŸ’¾ Wasted space on duplicate data | âœ… **Automatic dedup with 2-3x savings** |
| âš¡ CPU overhead for compression | âœ… **Entropy detection skips random data** |
| âœ”ï¸ No integrity verification | âœ… **BLAKE3-MAC on every segment** |

### ğŸ¯ Proven Architecture

This MVP proves the core innovations outlined in the architecture documents:

âœ… **Dedup Over Encrypted Data** -- Deterministic encryption preserves space efficiency
âœ… **Adaptive Compression** -- LZ4/Zstd with entropy-based selection
âœ… **Content-Addressed Storage** -- BLAKE3 hashing enables global dedup
âœ… **Protocol Views** -- S3 API proves universal namespace works
âœ… **Space Efficiency** -- 2-3x savings maintained with encryption
âœ… **Key Management** -- Version-tracked derivation with rotation
âœ… **Integrity Verification** -- BLAKE3-MAC detects tampering

---

## ğŸ” Security & Encryption

### ğŸ’ The Core Innovation

Traditional encryption **destroys** deduplication:
```
Plaintext A + Random IV -> Ciphertext X
Plaintext A + Random IV -> Ciphertext Y (different!)
Result: Dedup FAILS âŒ
```

**ğŸš€ SPACE's breakthrough:**
```
Plaintext A -> Compress -> Hash -> Deterministic Tweak -> Ciphertext X
Plaintext A -> Compress -> Hash -> Same Tweak         -> Ciphertext X âœ…
Result: Dedup WORKS while maintaining encryption! ğŸ‰
```

### ğŸ›¡ï¸ Security Properties

| Property | Implementation | Strength |
|----------|----------------|----------|
| ğŸ”’ **Confidentiality** | XTS-AES-256 | 256-bit |
| âœ… **Integrity** | BLAKE3-MAC | 128-bit |
| ğŸ”— **Deduplication** | Deterministic tweaks | Preserved |
| ğŸ”‘ **Key Derivation** | BLAKE3-KDF | Cryptographic |
| ğŸ”„ **Key Rotation** | Version tracking | Zero downtime |
| ğŸ§¹ **Memory Safety** | Zeroization | Keys cleared on drop |

### âš¡ Quick Encryption Setup
```bash
# Generate 256-bit master key
export SPACE_MASTER_KEY=$(openssl rand -hex 32)

# Encryption now auto-enabled for all writes
# Read operations auto-decrypt when keys available
```

For detailed security documentation, see [ENCRYPTION_IMPLEMENTATION.md](docs/ENCRYPTION_IMPLEMENTATION.md)

---

## ğŸ—ºï¸ Roadmap

### âœ… Phase 1: Core Storage (COMPLETE)
- âœ… Capsule registry with persistent metadata
- âœ… NVRAM log simulator
- âœ… CLI for create/read operations
- âœ… 4MB automatic segmentation
- âœ… Integration tests

### âœ… Phase 2.1: Compression (COMPLETE)
- âœ… LZ4 fast compression
- âœ… Zstd balanced compression
- âœ… Entropy-based compression selection
- âœ… Policy-driven compression levels
- âœ… Compression statistics tracking

### âœ… Phase 2.2: Deduplication (COMPLETE)
- âœ… BLAKE3 content hashing
- âœ… Content-addressed storage (ContentHash -> SegmentId)
- âœ… Post-compression deduplication
- âœ… Dedup statistics and monitoring
- âœ… Reference counting (foundation for GC)

### âœ… Phase 2.3: Protocol Views (COMPLETE)
- âœ… S3-compatible REST API
- âœ… PUT/GET/HEAD/LIST/DELETE operations
- âœ… Protocol abstraction layer
- âœ… S3 server with Axum

### âœ… Phase 3.1: Encryption & Integrity (COMPLETE)
- âœ… XTS-AES-256 per-segment encryption
- âœ… Deterministic tweak derivation (preserves dedup)
- âœ… BLAKE3-MAC integrity verification
- âœ… Key management with BLAKE3-KDF
- âœ… Key rotation with version tracking
- âœ… Environment-based key configuration
- âœ… Memory zeroization for security
- âœ… 53 comprehensive tests

### âœ… Phase 3.2: Lifecycle Management (COMPLETE)
- âœ… Reference-counted segment tracking across capsules
- âœ… Startup refcount reconciliation on pipeline initialization
- âœ… Manual garbage collector for metadata reclamation

### âœ… Phase 3.3: Advanced Security (COMPLETE)
- âœ… Counting Bloom filters + registry plumbing
- âœ… Immutable audit log with BLAKE3 hash chains + TSA hooks
- âœ… SPIFFE + mTLS ingress middleware + refreshable allow-list
- âœ… Kyber hybrid crypto profile + segment metadata
- âœ… Security module + docs aligning Bloom/Audit/PQ/eBPF

### ğŸ”® Phase 4: Advanced Protocol Views
- ğŸ“‹ NVMe-oF block target (SPDK)
- ğŸ“‹ NFS v4.2 file export
- ğŸ“‹ FUSE filesystem mount
- ğŸ“‹ CSI driver for Kubernetes

### ğŸš€ Phase 5: Enterprise Features
- ğŸ“‹ Metro-sync replication
- ğŸ“‹ Policy compiler
- ğŸ“‹ Erasure coding (6+2)
- ğŸ“‹ Hardware offload (DPU/GPU)
- ğŸ“‹ Confidential compute enclaves

---

## âš¡ Performance Characteristics

### ğŸ—œï¸ Compression (Phase 2.1)

| Data Type | Algorithm | Compression Ratio | Throughput |
|-----------|-----------|-------------------|------------|
| ğŸ“ Text/logs | Zstd level 3 | 3-5x | ~500 MB/s |
| ğŸ“¦ Binary/mixed | LZ4 level 1 | 1.5-2.5x | ~2 GB/s |
| ğŸ² Random/encrypted | None (skipped) | 1.0x | ~5 GB/s |

### ğŸ”— Deduplication (Phase 2.2)

| Scenario | Dedup Ratio | Space Saved |
|----------|-------------|-------------|
| ğŸ’¿ VM images (identical) | 10-20x | 90-95% |
| ğŸ“‹ Log files (repeated) | 2-5x | 50-80% |
| ğŸ‘¤ User data (mixed) | 1.5-3x | 30-65% |
| âœ¨ Unique data | 1.0x | 0% |

### ğŸ” Encryption (Phase 3.1)

| Operation | Baseline | With Encryption | Overhead |
|-----------|----------|-----------------|----------|
| Write | 2.1 GB/s | 2.0 GB/s | +5% |
| Read | 3.5 GB/s | 3.2 GB/s | +9% |
| Dedup | Works | **Still Works** | 0% impact |

**ğŸ“Š Breakdown per 4MB segment:**
```
ğŸ—œï¸  Compression (LZ4):     ~0.5ms  (2.5 GB/s)
#ï¸âƒ£  Hashing (BLAKE3):      ~0.3ms  (13 GB/s)
ğŸ” Encryption (XTS-AES):  ~0.8ms  (5 GB/s with AES-NI)
âœ… MAC (BLAKE3):          ~0.3ms  (13 GB/s)
ğŸ’¾ NVRAM write:           ~0.1ms  (fsync)
--------------------------------
âš¡ Total:                 ~2.0ms per 4MB segment
```

### ğŸ“ˆ Overhead Summary

- #ï¸âƒ£ Hash computation (BLAKE3): ~2ms per 4MB segment
- ğŸ” Content store lookup: <1us (HashMap)
- ğŸ” Encryption overhead: <5% of write time
- âœ… MAC overhead: <1% of write time
- ğŸ”— Dedup overhead: <1% of write time
- **âš¡ Combined overhead: <10% increase in write latency**

---

## ğŸ¤ Contributing

This is an experimental platform exploring radical new storage architectures. We welcome:

- ğŸ› Bug reports and fixes
- ğŸ’¡ Architecture suggestions
- ğŸ“š Documentation improvements
- ğŸ§ª New test cases
- âš¡ Performance optimizations
- ğŸ”’ Security reviews

**ğŸ“ Before submitting PRs:**
1. âœ¨ Run `cargo fmt` and `cargo clippy`
2. âœ… Ensure all tests pass (`cargo test --workspace`)
3. ğŸ“– Update documentation for new features
4. ğŸ§ª Add tests for new functionality

---

## ğŸ“š Learn More

- ğŸ—ï¸ **[Architecture Overview](docs/architecture.md)** -- Full system design
- ğŸ”® **[Future State Architecture](docs/future_state_architecture.md)** -- Vision and roadmap
- ğŸ’¡ **[Patentable Concepts](docs/patentable_concepts.md)** - Novel mechanisms
- ğŸ”— **[Dedup Implementation](docs/DEDUP_IMPLEMENTATION.md)** - Phase 2.2 technical details
- ğŸ” **[Encryption Implementation](docs/ENCRYPTION_IMPLEMENTATION.md)** - **NEW: Phase 3 security details**
- ğŸŒ **[Protocol Views Integration](docs/protocol_views.md)** - CLI workflow for S3/NFS/block facades
- ğŸš€ **[S3 Quick Start](QUICKSTART_S3.md)** -- Protocol view demo
- ğŸ”¨ **[Build Guide](BUILD.md)** -- Compilation and testing

---

## ğŸ“œ License

**Apache 2.0** â€” Permissive open source license with patent grant

- âœ… Open use: commercial, research, and personal deployments are all allowed
- ğŸ“ Keep notices: retain copyright and license text when distributing
- ğŸ¤ Contributions: submitted patches are accepted under Apache 2.0 (see CONTRIBUTING.md)

[ğŸ“„ Full license details](LICENSE) | [ğŸ¤ Contribution guidelines](CONTRIBUTING.md)

### ğŸ¤ Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work shall be licensed as above, without any additional terms or conditions.

---

## ğŸ“Š Project Status

**ğŸ¯ Current Phase:** Phase 3.3 Complete (Advanced Security)
**ğŸ”¬ Stability:** Experimental -- API subject to change
**ğŸš€ Production Ready:** Not yet (educational/research purposes)

**âœ… What works today:**
- âœ… Capsule storage with compression and deduplication
- âœ… Counting Bloom + audit log (feature `advanced-security`)
- âœ… SPIFFE + mTLS gateway with optional eBPF + Kyber toggle
- âœ… **XTS-AES-256 encryption with integrity verification**
- âœ… **Deterministic encryption preserving deduplication**
- âœ… **Key management with rotation support**
- âœ… S3-compatible REST API
- âœ… CLI tools for basic operations
- âœ… Persistent metadata and NVRAM log

**âš ï¸ Known limitations:**
- ğŸ“‹ Log-space reclamation pending (Phase 4)
- ğŸ“‹ CLI doesn't have --encrypt flag yet (Phase 3.2)
- ğŸ“‹ Single-node only (clustering = Phase 5)
- ğŸ“‹ No authentication/authorization (Phase 4)

---

## ğŸ¬ Quick Demo
```bash
# Build
cargo build --release

# Setup encryption (optional)
export SPACE_MASTER_KEY=$(openssl rand -hex 32)

# Create a file with repeated content
echo "SPACE STORAGE PLATFORM" > demo.txt
for i in {1..1000}; do echo "SPACE STORAGE PLATFORM" >> demo.txt; done

# First capsule - no dedup yet
./target/release/spacectl create --file demo.txt

# Second capsule - watch the dedup magic!
./target/release/spacectl create --file demo.txt

# Expected output:
# *  Dedup hit: Reusing segment 0 (saved 24576 bytes)
#  Segment 1: encrypted with key v1 (if SPACE_MASTER_KEY set)
# [x] Capsule ...: 5.2x compression, 1 dedup hits (24576 bytes saved)  encrypted

# Start S3 server
./target/release/spacectl serve-s3 --port 8080 &

# Access via S3 API
curl -X PUT http://localhost:8080/demo/test.txt -d "Hello SPACE!"
curl http://localhost:8080/demo/test.txt
```

### ğŸ“‚ Explore NFS and Block views
```powershell
# Create directories and write a file via the NFS view
spacectl nfs mkdir --path /lab/results
spacectl nfs write --path /lab/results/report.json --file report.json
spacectl nfs list --path /lab/results
spacectl nfs read --path /lab/results/report.json > fetched.json

# Provision a 32MiB block volume and write a sector
spacectl block create vol1 33554432
spacectl block write vol1 4096 --file sector.bin
spacectl block read vol1 4096 --length 512 > sector.verify
spacectl block delete vol1
```

### ğŸ“Š Telemetry & Logging
- ğŸ¨ `SPACE_LOG_FORMAT` controls console output (`compact` by default, set to `json` for structured logs).
- ğŸ“ `RUST_LOG` follows `tracing` filters (example: `RUST_LOG=info,space=debug`).
- ğŸ“¡ All pipeline stages emit structured spans/events (`pipeline::compression`, `telemetry::compression`) for the future telemetry hub.
- ğŸš¨ Primary error surfaces for on-call runbooks:
  | Code | Level | Description | Suggested Action |
  |------|-------|-------------|------------------|
  | `CompressionError::EntropySkip` | `WARN` | High-entropy payload skipped compression, includes entropy + segment size | Optional; review workload mix if persistent |
  | `CompressionError::IneffectiveRatio` | `INFO` | Compression reverted due to poor ratio, includes achieved ratio | Tune policy thresholds if noisy |
  | `PipelineError::Compression` | `ERROR` | Compression subsystem hard-failed for a segment (includes index) | Retry segment; inspect codec health |
  | `PipelineError::Nvram` / `PipelineError::Registry` | `ERROR` | Storage metadata IO failure with operation identifier | Investigate backing store, retry once safe |
  | `PipelineError::Telemetry` | `WARN` | Downstream telemetry sink rejected structured event | Defer to hub health; logs still written locally |

---

<div align="center">

**Built with ğŸ¦€ Rust**

*Breaking storage silos, one encrypted capsule at a time.* ğŸš€

**ğŸ‰ Phase 3.3 Complete: Compression âœ… | Dedup âœ… | Protocol Views âœ… | Advanced Security âœ…**

---

[ğŸ› Report Bug](https://github.com/your-org/space/issues) â€¢ [ğŸ’¡ Request Feature](https://github.com/your-org/space/issues) â€¢ [ğŸ’¬ Discussions](https://github.com/your-org/space/discussions)

**â­ Star us on GitHub if you find this project interesting! â­**

</div>




